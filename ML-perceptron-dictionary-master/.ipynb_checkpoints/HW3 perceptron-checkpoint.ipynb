{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T21:05:42.440325Z",
     "start_time": "2018-02-22T21:05:41.506414Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T21:05:42.452388Z",
     "start_time": "2018-02-22T21:05:42.442874Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_and_Y_train (3000, 820)\n",
      "[[ 0.  1.  3. ...,  0.  0.  5.]\n",
      " [ 0.  0.  3. ...,  0.  0.  1.]\n",
      " [ 0.  0.  1. ...,  0.  0.  4.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  6.]\n",
      " [ 0.  0.  2. ...,  0.  0.  1.]\n",
      " [ 0.  0.  2. ...,  0.  0.  5.]]\n",
      "X_and_Y_test is (1000, 820)\n",
      "[[  0.   1.   0. ...,   0.   0.   2.]\n",
      " [  0.   0.   3. ...,   0.   0.   1.]\n",
      " [  0.   0.  45. ...,   0.   0.   2.]\n",
      " ..., \n",
      " [  0.   0.   1. ...,   0.   0.   6.]\n",
      " [  0.   0.   4. ...,   0.   0.   6.]\n",
      " [  0.   0.   4. ...,   0.   0.   6.]]\n"
     ]
    }
   ],
   "source": [
    "# 1  import data \n",
    "X_and_Y_train = np.loadtxt('data/pa3train.txt', delimiter=' ')\n",
    "print \"X_and_Y_train\", X_and_Y_train.shape\n",
    "print  X_and_Y_train\n",
    "\n",
    "X_and_Y_test = np.loadtxt('data/pa3test.txt', delimiter=' ')\n",
    "print \"X_and_Y_test is\", X_and_Y_test.shape\n",
    "print X_and_Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part1 training and test error for round 2, 3, 4: \n",
    "# basic perceptron, voted perceptron and avg perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1090, 820)\n",
      "[[  0.   0.   3. ...,   0.   0.   1.]\n",
      " [  0.   0.  12. ...,   0.   0.   2.]\n",
      " [  0.   1.   2. ...,   0.   0.   2.]\n",
      " ..., \n",
      " [  0.   0.   5. ...,   0.   0.   2.]\n",
      " [  0.   0.   3. ...,   0.   0.   1.]\n",
      " [  0.   0.   2. ...,   0.   0.   1.]]\n",
      "(377, 820)\n",
      "[[  0.   1.   0. ...,   0.   0.   2.]\n",
      " [  0.   0.   3. ...,   0.   0.   1.]\n",
      " [  0.   0.  45. ...,   0.   0.   2.]\n",
      " ..., \n",
      " [  0.   0.   2. ...,   0.   0.   2.]\n",
      " [  0.   0.   7. ...,   0.   0.   2.]\n",
      " [  0.   0.   1. ...,   0.   0.   1.]]\n"
     ]
    }
   ],
   "source": [
    "# obtain subset containing only label 1 or 2\n",
    "def subset(data):\n",
    "    datalist = []\n",
    "    for i in range(data.shape[0]): \n",
    "        if (data[i,819] == 1 or data[i,819] == 2):\n",
    "            datalist.append(data[i,:])\n",
    "    dataArray = np.array(datalist)\n",
    "    return dataArray\n",
    "\n",
    "\n",
    "X_and_Y_train_subset = subset(X_and_Y_train)\n",
    "X_and_Y_test_subset = subset(X_and_Y_test)\n",
    "\n",
    "print X_and_Y_train_subset.shape\n",
    "print X_and_Y_train_subset\n",
    "print X_and_Y_test_subset.shape\n",
    "print X_and_Y_test_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1090, 820)\n",
      "[[  0.   0.   3. ...,   0.   0.   1.]\n",
      " [  0.   0.  12. ...,   0.   0.  -1.]\n",
      " [  0.   1.   2. ...,   0.   0.  -1.]\n",
      " ..., \n",
      " [  0.   0.   5. ...,   0.   0.  -1.]\n",
      " [  0.   0.   3. ...,   0.   0.   1.]\n",
      " [  0.   0.   2. ...,   0.   0.   1.]]\n",
      "(377, 820)\n",
      "[[  0.   1.   0. ...,   0.   0.  -1.]\n",
      " [  0.   0.   3. ...,   0.   0.   1.]\n",
      " [  0.   0.  45. ...,   0.   0.  -1.]\n",
      " ..., \n",
      " [  0.   0.   2. ...,   0.   0.  -1.]\n",
      " [  0.   0.   7. ...,   0.   0.  -1.]\n",
      " [  0.   0.   1. ...,   0.   0.   1.]]\n"
     ]
    }
   ],
   "source": [
    "# convert data to 1(class1) and -1(class2)\n",
    "def converter(data):\n",
    "    for i in range(data.shape[0]):\n",
    "        if data[i,819] == 1:       \n",
    "            data[i,819] = 1\n",
    "        else:\n",
    "            data[i,819] = -1\n",
    "            \n",
    "converter(X_and_Y_train_subset)\n",
    "print X_and_Y_train_subset.shape\n",
    "print X_and_Y_train_subset\n",
    "\n",
    "converter(X_and_Y_test_subset)\n",
    "print X_and_Y_test_subset.shape\n",
    "print X_and_Y_test_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T21:05:42.491013Z",
     "start_time": "2018-02-22T21:05:42.465003Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2) Implement the perceptron\n",
    "# Notice that since Data is provided in float,\n",
    "# the creaeted 1D array \n",
    "def zeroArrayMaker(n):\n",
    "    return np.array([0.0] * n)\n",
    "\n",
    "def basic_percetron(data, w):\n",
    "    counter=0\n",
    "    for t in range(data.shape[0]):\n",
    "        if (data[t,819] * np.dot(w,data[t,:819]) ) <= 0:\n",
    "            counter+=1\n",
    "            w += data[t,819] * data[t,:819]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Basic_perceptron_predict_error(data, w):\n",
    "    wrong_num = 0.0\n",
    "    total_num = data.shape[0]\n",
    "    for i in range(data.shape[0]): \n",
    "        if np.sign(np.dot(w,data[i,:819])) != data[i,819]:\n",
    "            wrong_num+=1.0\n",
    "    return wrong_num/total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------basic perceptron-------\n",
      "\n",
      "round 1\n",
      "training error is:  0.0412844036697\n",
      "testing error is:  0.053050397878\n",
      "\n",
      "round 2\n",
      "training error is:  0.0403669724771\n",
      "testing error is:  0.0610079575597\n",
      "\n",
      "round 3\n",
      "training error is:  0.0211009174312\n",
      "testing error is:  0.0450928381963\n",
      "\n",
      "round 4\n",
      "training error is:  0.0192660550459\n",
      "testing error is:  0.0477453580902\n"
     ]
    }
   ],
   "source": [
    "#run perceptron 4 rounds\n",
    "print \"------basic perceptron-------\"\n",
    "w = zeroArrayMaker(X_and_Y_train_subset.shape[1]-1)\n",
    "for i in range (4):\n",
    "    basic_percetron(X_and_Y_train_subset,w)\n",
    "    print \"\\nround\",i+1\n",
    "    print \"training error is: \",Basic_perceptron_predict_error(X_and_Y_train_subset,w)\n",
    "    print \"testing error is: \",Basic_perceptron_predict_error(X_and_Y_test_subset,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Voted_perceptron_predict_error(data,w_list,c_list):\n",
    "    wrong_num = 0.0\n",
    "    total_num = data.shape[0]\n",
    "    \n",
    "    for i in range(data.shape[0]): \n",
    "        total = 0.0                        # !!! each time total need to be refreshed \n",
    "        for j in range(len(w_list)):\n",
    "            total += c_list[j] * np.sign(np.dot(w_list[j],data[i,:819]))\n",
    "        if np.sign(total) != data[i,819]:\n",
    "            wrong_num+=1.0\n",
    "            \n",
    "    return wrong_num/total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def advanced_percetron(data,w_list,c_list, best_w,best_c):\n",
    "    counter = best_c \n",
    "    w = best_w\n",
    "    \n",
    "    for t in range(data.shape[0]):\n",
    "        if (data[t,819] * np.dot(w,data[t,:819])) <= 0:\n",
    "            w_list.append(w)\n",
    "            c_list.append(counter)\n",
    "            w = w + data[t,819] * data[t,:819]  # 5hrs debuging !!!>_<\n",
    "                                                # a += 不能随便用啊！非scalar ???\n",
    "            counter = 1      # re-init num of labels passed\n",
    "        else:\n",
    "            counter += 1     # increase counter by 1\n",
    "\n",
    "    w_list.append(w)\n",
    "    c_list.append(counter)\n",
    "    \n",
    "    return w_list,c_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Voted perceptron-------\n",
      "\n",
      "round 1\n",
      "training error is:  0.0669724770642\n",
      "testing error is:  0.0875331564987\n",
      "\n",
      "round 2\n",
      "training error is:  0.0403669724771\n",
      "testing error is:  0.0610079575597\n",
      "\n",
      "round 3\n",
      "training error is:  0.0293577981651\n",
      "testing error is:  0.0450928381963\n",
      "\n",
      "round 4\n",
      "training error is:  0.0247706422018\n",
      "testing error is:  0.0450928381963\n"
     ]
    }
   ],
   "source": [
    "#run perceptron 4 rounds\n",
    "print \"------Voted perceptron-------\"\n",
    "w_list = [] \n",
    "c_list = [] \n",
    "best_w = zeroArrayMaker(X_and_Y_train_subset.shape[1]-1)   # init an array with all 0\n",
    "best_c = 0     # num of labels passed for this classifier\n",
    "\n",
    "for i in range (4):\n",
    "    w_list,c_list = advanced_percetron(X_and_Y_train_subset,w_list,c_list,best_w,best_c)\n",
    "    \n",
    "    print \"\\nround\",i+1\n",
    "    print \"training error is: \",\\\n",
    "    Voted_perceptron_predict_error(X_and_Y_train_subset,w_list,c_list)\n",
    "    print \"testing error is: \",\\\n",
    "    Voted_perceptron_predict_error(X_and_Y_test_subset,w_list,c_list)\n",
    "\n",
    "    #pass best w and c for next pass\n",
    "    best_w = w_list[-1]\n",
    "    best_c = c_list[-1]\n",
    "    w_list.pop()\n",
    "    c_list.pop()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_Avg_perceptron(w_list, c_list):\n",
    "    avg_w = zeroArrayMaker(819)\n",
    "    for j in range(len(w_list)):\n",
    "        avg_w = avg_w + np.dot(w_list[j], c_list[j])\n",
    "    return avg_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Avg_perceptron_predict_error(data, avg_w):\n",
    "    wrong_num = 0.0 \n",
    "    total_num = data.shape[0]\n",
    "    for i in range(data.shape[0]): \n",
    "        if np.sign(np.dot(avg_w,data[i,:819])) != data[i,819]:\n",
    "            wrong_num+=1.0\n",
    "    return wrong_num/total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------average perceptron-------\n",
      "\n",
      "round 1\n",
      "training error is:  0.0798165137615\n",
      "testing error is:  0.116710875332\n",
      "\n",
      "round 2\n",
      "training error is:  0.054128440367\n",
      "testing error is:  0.0822281167109\n",
      "\n",
      "round 3\n",
      "training error is:  0.0376146788991\n",
      "testing error is:  0.0610079575597\n",
      "\n",
      "round 4\n",
      "training error is:  0.0339449541284\n",
      "testing error is:  0.0503978779841\n"
     ]
    }
   ],
   "source": [
    "#run perceptron 4 rounds\n",
    "print \"------average perceptron-------\"\n",
    "w_list = [] \n",
    "c_list = [] \n",
    "best_w = zeroArrayMaker(X_and_Y_train_subset.shape[1]-1)   # init an array with all 0\n",
    "best_c = 0 \n",
    "\n",
    "for i in range (4):\n",
    "    w_list,c_list = advanced_percetron(X_and_Y_train_subset,w_list,c_list,best_w,best_c)\n",
    "    \n",
    "    #calculate avg perceptron\n",
    "    avg_w = get_Avg_perceptron(w_list,c_list)\n",
    "\n",
    "    train_err = Avg_perceptron_predict_error(X_and_Y_train_subset, avg_w)\n",
    "    test_err = Avg_perceptron_predict_error(X_and_Y_test_subset, avg_w)\n",
    "\n",
    "    print \"\\nround\",i+1\n",
    "    print \"training error is: \",train_err\n",
    "    print \"testing error is: \",test_err\n",
    "    \n",
    "    #pass best w and c for next pass\n",
    "    best_w = w_list[-1]\n",
    "    best_c = c_list[-1]\n",
    "    w_list.pop()\n",
    "    c_list.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part2  \n",
    "Find the three coordinates in w avg with the highest and lowest values. What are the words (from\n",
    "pa3dictionary.txt) that correspond to these coordinates? The three highest coordinates are those\n",
    "words whose presence indicates the positive class most strongly, and the three lowest coordinates are\n",
    "those words whose presence indicates the negative class most strongly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------average perceptron running 3 rounds-------\n",
      "lowest 3: [-225566.0, -122322.0, -114186.0]\n",
      "lowest 3 corrodinates: [ 78 469 393]\n",
      "highest 3: [386081.0, 235238.0, 142301.0]\n",
      "highest 3 corrodinates: [438 466 203]\n"
     ]
    }
   ],
   "source": [
    "print \"------average perceptron running 3 rounds-------\"\n",
    "w_list = [] \n",
    "c_list = [] \n",
    "best_w = zeroArrayMaker(X_and_Y_train_subset.shape[1]-1)   # init an array with all 0\n",
    "best_c = 0\n",
    "\n",
    "for i in range(3):\n",
    "    w_list,c_list = advanced_percetron(X_and_Y_train_subset,w_list,c_list, best_w,best_c = 0 )\n",
    "     \n",
    "    best_w = w_list[-1]\n",
    "    best_c = c_list[-1]\n",
    "    w_list.pop()\n",
    "    c_list.pop()\n",
    "\n",
    "#produce the avg percetptron after 3 rounds\n",
    "avg_w = get_Avg_perceptron(w_list, c_list)\n",
    "\n",
    "print \"lowest 3:\",sorted(avg_w, reverse=False)[:3]\n",
    "lowest_3 = np.argsort(avg_w)[:3]\n",
    "print \"lowest 3 corrodinates:\",lowest_3\n",
    "\n",
    "print \"highest 3:\",sorted(avg_w, reverse=True)[:3]\n",
    "highest_3 = np.argsort(avg_w)[len(avg_w)-3:][::-1]  \n",
    "print \"highest 3 corrodinates:\",highest_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dictionary has:  819  words\n",
      "\n",
      "words correspond to highest 3 coordinates are:\n",
      "file\n",
      "program\n",
      "line\n",
      "\n",
      "words correspond to lowest 3 coordinates are:\n",
      "he\n",
      "team\n",
      "game\n"
     ]
    }
   ],
   "source": [
    "with open('data/pa3dictionary.txt', 'r') as myfile:\n",
    "    dictionary=myfile.read().replace('\\n', '')\n",
    "dictionary_list = dictionary.split()\n",
    "print \"the dictionary has: \",len(dictionary_list),\" words\"\n",
    "\n",
    "print \"\\nwords correspond to highest 3 coordinates are:\"\n",
    "for i in (highest_3): print dictionary_list[i]\n",
    "    \n",
    "print \"\\nwords correspond to lowest 3 coordinates are:\" \n",
    "for i in (lowest_3): print dictionary_list[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part3 one-vs-all multi-class classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  3. ...,  0.  0.  0.]\n",
      " [ 0.  0.  3. ...,  0.  0.  0.]\n",
      " [ 0.  0.  1. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  2. ...,  0.  0.  0.]\n",
      " [ 0.  0.  2. ...,  0.  0.  0.]]\n",
      "[ 5.  1.  4. ...,  6.  1.  5.]\n",
      "(1000, 819)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "# 1  import data \n",
    "X_and_Y_train = np.loadtxt('data/pa3train.txt', delimiter=' ')\n",
    "X_train = X_and_Y_train[:,:819]\n",
    "Y_train = X_and_Y_train[:,819]\n",
    "print X_train\n",
    "print Y_train\n",
    "\n",
    "X_and_Y_test = np.loadtxt('data/pa3test.txt', delimiter=' ')\n",
    "X_test = X_and_Y_test[:,:819]\n",
    "Y_test = X_and_Y_test[:,819]\n",
    "print X_test.shape\n",
    "print Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_label(label_array):\n",
    "    label_num_list = [0,0,0,0,0,0]\n",
    "    for i in range(label_array.shape[0]):\n",
    "        for j in range(6):\n",
    "            if label_array[i] == (j+1):\n",
    "                label_num_list[j] += 1\n",
    "    return label_num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of labels(1---6) in test data:\n",
      " N list[] =  [185, 192, 175, 184, 156, 108]\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "#2. count Nj: the number of test examples that have label j\n",
    "N_list = count_label(Y_test)\n",
    "print \"number of labels(1---6) in test data:\\n N list[] = \", N_list\n",
    "print sum(N_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3. convert data to 1(class1) and -1(the rest)\n",
    "def converter(data_label):\n",
    "    list_of_label_array = []  \n",
    "    \n",
    "    for label in [1,2,3,4,5,6]:\n",
    "        tempdata = zeroArrayMaker(data_label.shape[0])  #re-initialization\n",
    "        for i in range(data_label.shape[0]):\n",
    "            if data_label[i] == label:  \n",
    "                tempdata[i] = 1\n",
    "            else:\n",
    "                tempdata[i] = -1\n",
    "        list_of_label_array.append(tempdata)  # OR np.array(tempdata)\n",
    "                    # np array will initialize the array using differnt address\n",
    "    return list_of_label_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-1.,  1., -1., ..., -1.,  1., -1.]), array([-1., -1., -1., ..., -1., -1., -1.]), array([-1., -1., -1., ..., -1., -1., -1.]), array([-1., -1.,  1., ..., -1., -1., -1.]), array([ 1., -1., -1., ..., -1., -1.,  1.]), array([-1., -1., -1., ...,  1., -1., -1.])]\n"
     ]
    }
   ],
   "source": [
    "coverted_train_label_List = converter(Y_train)\n",
    "print coverted_train_label_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. train a list of 6 classifiers (One vs All)\n",
    "\n",
    "def basic_percetron(data, coverted_train_label_List):\n",
    "    w = zeroArrayMaker(X_and_Y_train_subset.shape[1]-1)\n",
    "    counter=0\n",
    "    for t in range(data.shape[0]):\n",
    "        if (coverted_train_label_List[t] * np.dot(w,data[t,:819]) ) <= 0:\n",
    "            counter+=1\n",
    "            w = w + coverted_train_label_List[t] * data[t,:819]   \n",
    "    return w\n",
    "            \n",
    "# train 6 perceptron classifiers C1 ... C6 stored in w_list\n",
    "w_list = []\n",
    "\n",
    "# For each class i = 1 ... 6, \n",
    "# run a single pass of the perceptron algorithm on the training dataset to\n",
    "# compute a linear classifier separating the training data points in class i \n",
    "# from the training data points not in class i. Call this classifier Ci.\n",
    "for i in range (6):\n",
    "    w = basic_percetron(X_train, coverted_train_label_List[i])\n",
    "    w_list.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5. calculate the C matrix \n",
    "# Cij is the number of test examples that have label j \n",
    "# but are classified as label i by the classifier\n",
    "def Basic_perceptron_prediction(X_test, Y_test, w_list):\n",
    "    \n",
    "    C_matrix = np.array([[0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0],\\\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0],\\\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0]])  \n",
    "    \n",
    "    for i in range(X_test.shape[0]):        #for each data\n",
    "        \n",
    "        temp_list = []\n",
    "        for j in range(len(w_list)):        #for each of the 6 classifier\n",
    "            temp_list.append(np.sign(np.dot(w_list[j],X_test[i])))\n",
    "            \n",
    "        count_yes = 0\n",
    "        count_no = 0\n",
    "        yes_index = 0\n",
    "        for k in range(len(temp_list)):\n",
    "            if temp_list[k] == 1:\n",
    "                count_yes += 1\n",
    "                yes_index = k\n",
    "            else:\n",
    "                count_no += 1\n",
    "        \n",
    "        # only If Ci(x) = i for exactly one i = 1...6, then predict label i.\n",
    "        if count_yes == 1: \n",
    "                C_matrix[yes_index][int(Y_test[i])-1] += 1   #report the predicted label\n",
    "        else:\n",
    "                C_matrix[6][int(Y_test[i])-1] += 1   #report Dont know \n",
    "\n",
    "    return C_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of predicted labels(1---6 + Dont know) in test data:\n",
      " C matrix[][] =\n",
      "[[ 133.    1.    6.    4.    0.    0.]\n",
      " [   2.  126.    6.    5.    2.    2.]\n",
      " [   0.    3.   65.    0.    0.    3.]\n",
      " [   3.    1.    0.  127.    0.    0.]\n",
      " [   3.    6.   13.    1.  125.   13.]\n",
      " [   1.    2.    6.    0.   11.   53.]\n",
      " [  43.   53.   79.   47.   18.   37.]]\n"
     ]
    }
   ],
   "source": [
    "C_matrix = Basic_perceptron_prediction(X_test, Y_test, w_list)\n",
    "print \"number of predicted labels(1---6 + Dont know) in test data:\\n C matrix[][] =\\n\", C_matrix\n",
    "# print sum (C_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of labels(1---6) in test data:\n",
      " N list[] =  [185, 192, 175, 184, 156, 108]\n"
     ]
    }
   ],
   "source": [
    "print \"number of labels(1---6) in test data:\\n N list[] = \", N_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the confusion matrix is:\n",
      "[[ 0.71891892  0.00520833  0.03428571  0.02173913  0.          0.        ]\n",
      " [ 0.01081081  0.65625     0.03428571  0.02717391  0.01282051  0.01851852]\n",
      " [ 0.          0.015625    0.37142857  0.          0.          0.02777778]\n",
      " [ 0.01621622  0.00520833  0.          0.69021739  0.          0.        ]\n",
      " [ 0.01621622  0.03125     0.07428571  0.00543478  0.80128205  0.12037037]\n",
      " [ 0.00540541  0.01041667  0.03428571  0.          0.07051282  0.49074074]\n",
      " [ 0.23243243  0.27604167  0.45142857  0.25543478  0.11538462  0.34259259]]\n"
     ]
    }
   ],
   "source": [
    "#6. calculate the Confusion matrix  called M_matrix\n",
    "# The entry of the matrix at row i and column j is Cij/Nj\n",
    "M_matrix = np.array([[0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0],\\\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0],\\\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0]]) \n",
    "\n",
    "for i in range(M_matrix.shape[0]):\n",
    "    for j in range (M_matrix.shape[1]):\n",
    "        M_matrix[i][j] = C_matrix[i][j]/N_list[j]\n",
    "\n",
    "print \"the confusion matrix is:\\n\",M_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "63px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
