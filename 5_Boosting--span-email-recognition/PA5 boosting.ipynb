{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T21:05:42.440325Z",
     "start_time": "2018-02-22T21:05:41.506414Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary size:  (4003,)\n",
      "training_set (450, 4004)\n",
      "test_set (129, 4004)\n"
     ]
    }
   ],
   "source": [
    "#load data \n",
    "\n",
    "dictionary = np.loadtxt('data/pa5dictionary.txt',dtype='string',delimiter=' ')\n",
    "training_set = np.loadtxt('data/pa5train.txt',delimiter=' ')\n",
    "test_set = np.loadtxt('data/pa5test.txt',delimiter=' ')\n",
    "\n",
    "print \"dictionary size: \",dictionary.shape\n",
    "print \"training_set\",training_set.shape\n",
    "print \"test_set\", test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict whether this is a spam email or not,\n",
    "#return 1 for spam, y for not spam\n",
    "def weak_classifer(feature_in_datapoint, pos_or_neg):\n",
    "    if pos_or_neg == 1:\n",
    "        if feature_in_datapoint == 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    if pos_or_neg == -1:\n",
    "        if feature_in_datapoint == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this boosting fucniton takes the input of data, and number of rounds to run \n",
    "# and returns a list of classifiers and a list of weighted errs which can \n",
    "# be used as the final classifier for making prediction\n",
    "def boosting(dataset, round_num):\n",
    "    \n",
    "    weak_classifer_list = []    #tuple of feature index and (1 for hi+ and -a for hi-)\n",
    "    alpha_list = []\n",
    "    \n",
    "    #init the weights for each data point \n",
    "    weight_list = []\n",
    "    weight = 1.0/ float(dataset.shape[0])    \n",
    "    for i in range (dataset.shape[0]): \n",
    "        weight_list.append(weight)\n",
    "\n",
    "    for t in range(round_num):\n",
    "       \n",
    "        #-----find the best weak classifier from 4003*2 = 8006 classifiers---\n",
    "        err_W_ht = 1.0\n",
    "        for i in range (dataset.shape[1]-1):\n",
    "            error_w_hi = 0.0    #weighted error\n",
    "            \n",
    "            for datapoint in range (dataset.shape[0]):   \n",
    "                #hi,+\n",
    "                if dataset[datapoint][i] == 1:\n",
    "                    #predict spam\n",
    "                    if dataset[datapoint][4003] == -1:\n",
    "                        error_w_hi += weight_list[datapoint]\n",
    "                if dataset[datapoint][i] == 0:\n",
    "                    #predict not spam\n",
    "                    if dataset[datapoint][4003] == 1:\n",
    "                        error_w_hi += weight_list[datapoint]\n",
    "\n",
    "            #hi,-  is simply calc by subtracting correct1 from num of datapoints\n",
    "            error_w_hi_2 = 1.0 - error_w_hi\n",
    "\n",
    "            #compare hi,+ and hi,- to see which is better for predicting this feature \n",
    "            if error_w_hi < error_w_hi_2:\n",
    "                error = error_w_hi\n",
    "                pos_or_neg  = 1\n",
    "            else:\n",
    "                error = error_w_hi_2\n",
    "                pos_or_neg  = -1\n",
    "\n",
    "            #update if error is reduced\n",
    "            if(error < err_W_ht):\n",
    "                err_W_ht = error\n",
    "                final_feature = i\n",
    "                final_pos_or_neg = pos_or_neg   \n",
    "        \n",
    "        weak_classifer_list.append((final_feature,final_pos_or_neg))\n",
    "             \n",
    "        #calc alpha for classifer ht from weighted err: err_W_ht\n",
    "        alpha_t =  0.5 * np.log((1-err_W_ht)/err_W_ht)\n",
    "        alpha_list.append(alpha_t)\n",
    "        \n",
    "        #calc nomalization const: Z,\n",
    "        Z =  (1-err_W_ht)*np.exp(-alpha_t) + err_W_ht*np.exp(alpha_t)\n",
    "        \n",
    "        #update weights for all datapoints in the next run\n",
    "        for datapoint in range(dataset.shape[0]):\n",
    "            #if correctly classified \n",
    "            if weak_classifer(dataset[datapoint][final_feature],final_pos_or_neg) == dataset[datapoint][4003]:\n",
    "                weight_list[datapoint] = weight_list[datapoint] * np.exp(-alpha_t) / Z\n",
    "            else:\n",
    "                weight_list[datapoint] = weight_list[datapoint] * np.exp(alpha_t) / Z\n",
    "            \n",
    "    return weak_classifer_list,alpha_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(dataset, weak_classifer_list, alpha_list):\n",
    "    error_data = 0.0\n",
    "    for datapoint in range(dataset.shape[0]):\n",
    "        total = 0.0\n",
    "        for t in range(len(weak_classifer_list)):\n",
    "            total += alpha_list[t] * weak_classifer( dataset[datapoint][weak_classifer_list[t][0]], weak_classifer_list[t][1])\n",
    "        if ( np.sign(total) != dataset[datapoint][4003]):\n",
    "            error_data += 1\n",
    "    return error_data/dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weak_classifer_list,alpha_list =  boosting(training_set,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error after 4 rounds:  0.0511111111111\n",
      "test error after 4 rounds:  0.0387596899225\n"
     ]
    }
   ],
   "source": [
    "print \"train error after 4 rounds: \", predict(training_set,weak_classifer_list,alpha_list)\n",
    "print \"test error after 4 rounds: \", predict(test_set,weak_classifer_list,alpha_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training error and test error output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error after 3 rounds:  0.0644444444444\n",
      "test error after 3 rounds:  0.0387596899225\n"
     ]
    }
   ],
   "source": [
    "weak_classifer_list,alpha_list =  boosting(training_set,3)\n",
    "print \"training error after 3 rounds: \", predict(training_set,weak_classifer_list,alpha_list)\n",
    "print \"test error after 3 rounds: \", predict(test_set,weak_classifer_list,alpha_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error after 7 rounds:  0.0288888888889\n",
      "test error after 7 rounds:  0.031007751938\n"
     ]
    }
   ],
   "source": [
    "weak_classifer_list,alpha_list =  boosting(training_set,7)\n",
    "print \"training error after 7 rounds: \", predict(training_set,weak_classifer_list,alpha_list)\n",
    "print \"test error after 7 rounds: \", predict(test_set,weak_classifer_list,alpha_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error after 10 rounds:  0.0155555555556\n",
      "test error after 10 rounds:  0.0387596899225\n"
     ]
    }
   ],
   "source": [
    "weak_classifer_list,alpha_list =  boosting(training_set,10)\n",
    "print \"training error after 10 rounds: \", predict(training_set,weak_classifer_list,alpha_list)\n",
    "print \"test error after 10 rounds: \", predict(test_set,weak_classifer_list,alpha_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error after 15 rounds:  0.0\n",
      "test error after 15 rounds:  0.0232558139535\n"
     ]
    }
   ],
   "source": [
    "weak_classifer_list,alpha_list =  boosting(training_set,15)\n",
    "print \"training error after 15 rounds: \", predict(training_set,weak_classifer_list,alpha_list)\n",
    "print \"test error after 15 rounds: \", predict(test_set,weak_classifer_list,alpha_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error after 20 rounds:  0.0\n",
      "test error after 20 rounds:  0.0232558139535\n"
     ]
    }
   ],
   "source": [
    "weak_classifer_list,alpha_list =  boosting(training_set,20)\n",
    "print \"training error after 20 rounds: \", predict(training_set,weak_classifer_list,alpha_list)\n",
    "print \"test error after 20 rounds: \", predict(test_set,weak_classifer_list,alpha_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notice that after15 rounds of boosting, the training err was reduced to 0,\n",
    "which is caused by overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on the dictionary file, write down the words corresponding to the weak learners chosen in the first 10 rounds of boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error after 7 rounds:  0.0155555555556\n",
      "test error after 7 rounds:  0.0387596899225\n"
     ]
    }
   ],
   "source": [
    "weak_classifer_list,alpha_list =  boosting(training_set,10)\n",
    "print \"training error after 7 rounds: \", predict(training_set,weak_classifer_list,alpha_list)\n",
    "print \"test error after 7 rounds: \", predict(test_set,weak_classifer_list,alpha_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3018, -1), (2001, 1), (1423, -1), (3783, 1), (2339, -1), (2089, 1), (620, -1), (1328, 1), (3899, -1), (886, 1)]\n"
     ]
    }
   ],
   "source": [
    "print weak_classifer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the words in dictionary are: \n",
      "remove\n",
      "language\n",
      "free\n",
      "university\n",
      "money\n",
      "linguistic\n",
      "click\n",
      "fax\n",
      "want\n",
      "de\n"
     ]
    }
   ],
   "source": [
    "print \"the words in dictionary are: \"\n",
    "for i in range(len(weak_classifer_list)):\n",
    "    print dictionary[weak_classifer_list[i][0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "63px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
